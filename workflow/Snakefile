import re
import subprocess as sp
from pathlib import Path
import pandas as pd

from snakemake.utils import available_cpu_count

IN_GENOMES = Path(config["genomes"])
IN_QUERIES_DIR = Path(config["queries"])
IN_BLAST_FIELDS = Path("config/blast_fields.tsv")

assert IN_GENOMES.exists(), "Input genome assembly list file not found."
assert IN_QUERIES_DIR.exists(), "Input query directory not found."
assert IN_BLAST_FIELDS.exists(), "Input blast fields file not found."

RESULTS = Path(config["results"])
RESULTS_GENOMES = RESULTS / "genomes"


THREADS = (
    available_cpu_count() if config["threads"] == "all" else int(config["threads"])
)

GENOME_REGEX = r"GC[AF]_\d+\.\d"


wildcard_constraints:
    genome=GENOME_REGEX,


BLAST_FIELDS_DF = pd.read_table(
    IN_BLAST_FIELDS,
    sep="\t",
    comment="#",
)
BLAST_FIELDS = " ".join(list(BLAST_FIELDS_DF.field))


GENOMES_DF = pd.read_table(
    IN_GENOMES, names=("genome",), delim_whitespace=True, comment="#"
)

genome_matches = [bool(re.match(GENOME_REGEX, g)) for g in GENOMES_DF.genome]
GENOMES_DF = GENOMES_DF.loc[genome_matches, :].sort_values("genome")
GENOMES = list(GENOMES_DF.genome)

GENOMES_SORTED = str(IN_GENOMES.parent / f"{IN_GENOMES.stem}_sorted{IN_GENOMES.suffix}")


def ALL_BLASTS(queries_dir, genomes_dir, genomes):
    queries = [query for query in queries_dir.iterdir() if query.suffix == ".faa"]
    out = list()
    for query in queries:
        for genome in genomes:
            blast_out = genomes_dir / genome / f"{genome}_{query.stem}.tsv"
            out.append(str(blast_out))
    return out


def ALL_BINDED(queries_dir, results_dir):
    out = list()
    for query in queries_dir.iterdir():
        out.append(str(results_dir / f"{query.stem}.tsv"))
    return out


rule all:
    input:
        ALL_BINDED(IN_QUERIES_DIR, RESULTS) + [GENOMES_SORTED],


rule help:
    shell:
        "bat workflow/Snakefile"


rule sort_genomes:
    input:
        f"{IN_GENOMES}",
    output:
        sorted=str(GENOMES_SORTED),
    run:
        GENOMES_DF.to_csv(output.sorted, header=False, index=False)


rule download_genome:
    output:
        faa=f"{RESULTS_GENOMES}/{{genome}}/{{genome}}.faa",
        gff=f"{RESULTS_GENOMES}/{{genome}}/{{genome}}.gff",
    shell:
        """
        mkdir -p {RESULTS_GENOMES}/{wildcards.genome}
        workflow/scripts/download_genome.py --include protein gff3 --out-dir {RESULTS_GENOMES}/{wildcards.genome} -- {wildcards.genome}
        """


rule makedb:
    input:
        faa=rules.download_genome.output.faa,
    output:
        db=f"{RESULTS_GENOMES}/{{genome}}/{{genome}}.dmnd",
    params:
        db=f"{RESULTS_GENOMES}/{{genome}}/{{genome}}",
    shell:
        """
        diamond makedb --db {params.db} --in {input.faa}
        """


rule blastp:
    input:
        query=f"{IN_QUERIES_DIR}/{{query}}.faa",
        db=rules.makedb.output.db,
    output:
        tsv6=f"{RESULTS_GENOMES}/{{genome}}/{{genome}}_{{query}}.tsv",
    params:
        format=f"6 {BLAST_FIELDS}",  # Number 6 is for ncbi blast tabular format
        db=rules.makedb.params.db,
    shell:
        """
        diamond blastp --outfmt {params.format}\
            --out   {output.tsv6}\
            --db    {params.db}\
            --query {input.query}
        """


def blasts(wildcards):
    query = wildcards.query
    return [
        str(RESULTS_GENOMES / genome / f"{genome}_{query}.tsv") for genome in GENOMES
    ]


rule bind_blasts:
    input:
        blasts,
    output:
        f"{RESULTS}/{{query}}.tsv",
    shell:
        """
        cat {input} > {output}
        """
