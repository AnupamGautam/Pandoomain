import os
import re
import subprocess as sp
from pathlib import Path

import pandas as pd

configfile: "config/config.yaml"


def bold_red(msg: str) -> str:
    # error format
    # https://stackoverflow.com/questions/287871/how-do-i-print-colored-text-to-the-terminal
    FAIL = "\033[91m"
    ENDC = "\033[0m"
    BOLD = "\033[1m"
    # Can't use f"" format strings, cause the formater (snakefmt) introduces speces
    return FAIL + BOLD + msg + ENDC


def is_internet_on():
    # https://stackoverflow.com/questions/20913411/test-if-an-internet-connection-is-present-in-python
    import socket

    try:
        socket.create_connection(("1.1.1.1", 53))
        return True
    except OSError:
        return False


IN_GENOMES = Path(config["genomes"])
IN_QUERIES = Path(config["queries"])
IN_BLAST_FIELDS = Path("config/blast_fields.tsv")


TAXID = config["taxid"]  # if not None

assert is_internet_on(), bold_red("No network connection.")
assert IN_GENOMES.exists(), (
    bold_red("Input genome assembly list file not found.")
    + f"\nTried to look it up at: {IN_GENOMES}."
)

assert IN_QUERIES.exists(), (
    bold_red("Input query file not found.") + f"\nTried to look it up at: {IN_QUERIES}."
)
assert IN_BLAST_FIELDS.exists(), (
    bold_red("Input blast fields file not found.")
    + f"\nTried to look it up at: {IN_BLAST_FIELDS}."
)


RESULTS = Path(config["results"])
RESULTS_GENOMES = RESULTS / "genomes"


GENOME_REGEX = r"GC[AF]_\d+\.\d"


wildcard_constraints:
    genome=GENOME_REGEX,


DIAMOND_ARGS = config["diamond_args"]  # if not None ?
PAIR = config["pair"]  # if not None
FILTERING_DOMS = config["filtering_domains"]
# QUERY_ALIASES = config["query_aliases"] # better that R reads this


def sort_filter_genomes(path, filter_regex) -> list:
    # read, trim trailing white space and comments
    df = pd.read_table(path, names=("genome",), sep=r"\s+", comment="#")
    # filter and sort
    genome_matches = [bool(re.match(filter_regex, g)) for g in df.genome]
    df = df.loc[genome_matches, :].sort_values("genome")
    # write
    # df.to_csv(output, header=False, index=False)
    return list(df.genome)


def get_blast_fields(path) -> str:
    df = pd.read_table(
        path,
        sep="\t",
        comment="#",
    )
    return list(df.field)


GENOMES = sort_filter_genomes(IN_GENOMES, GENOME_REGEX)

ISCAN_HEADER_L = [
    "pid",
    "md5",
    "length",
    "analysis",
    "memberDB",
    "memberDB_txt",
    "start",
    "end",
    "score",
    "recommended",
    "date",
    "interpro",
    "interpro_txt",
    "GO",
    "residue",
]
ISCAN_HEADER = "\t".join(ISCAN_HEADER_L)

ISCAN_XML = Path(".iscan.xml")
ISCAN_TSV = Path("iscan.tsv")

BLASTS_FAA = Path("blasts.faa")
BLASTS_TSV = Path("blasts.tsv")
BLASTS_PID = Path(".blasts_pids.txt")

ALL_BLASTS = [
    str(RESULTS_GENOMES / f"{genome}" / f"{genome}_blast.tsv") for genome in GENOMES
]
BLAST_FIELDS = get_blast_fields(IN_BLAST_FIELDS)
BLAST_FORMAT = " ".join(BLAST_FIELDS)

BLAST_FORMAT_RENAMES = {"qseqid": "query", "sseqid": "pid"}
d = BLAST_FORMAT_RENAMES
blast_renamed = [d[i] if i in d.keys() else i for i in BLAST_FIELDS]

BLAST_HEADER = "\t".join(["genome"] + blast_renamed)


ALL_HITS = [
    str(RESULTS_GENOMES / f"{genome}" / f"{genome}_hits.tsv") for genome in GENOMES
]


# Default rule at the end of file


rule download_genome:
    output:
        faa=f"{RESULTS_GENOMES}/{{genome}}/{{genome}}.faa",
        gff=f"{RESULTS_GENOMES}/{{genome}}/{{genome}}.gff",
    params:
        include="protein gff3",
    retries: 3
    shell:
        """
        workflow/scripts/download_genome.py --include {params.include} --out-dir {RESULTS_GENOMES}/{wildcards.genome} -- {wildcards.genome}
        """


rule cds:
    input:
        gff=rules.download_genome.output.gff,
    output:
        cds=f"{RESULTS_GENOMES}/{{genome}}/{{genome}}_cds.tsv",
    shell:
        """
        workflow/scripts/reduce_gff2cds.R {input} >| {output}
        """


rule makedb:
    input:
        faa=rules.download_genome.output.faa,
    output:
        db=f"{RESULTS_GENOMES}/{{genome}}/{{genome}}.dmnd",
    params:
        db=f"{RESULTS_GENOMES}/{{genome}}/{{genome}}",
    shell:
        """
        diamond makedb --db {params.db} --in {input.faa}
        """


rule blastp:
    input:
        query=IN_QUERIES,
        db=rules.makedb.output.db,
    output:
        tsv6=f"{RESULTS_GENOMES}/{{genome}}/{{genome}}_blast.tsv",
    params:
        format=f"6 {BLAST_FORMAT}",  # Number 6 is for ncbi blast tabular format
        db=rules.makedb.params.db,
        extra_args=f"{DIAMOND_ARGS}",
    shell:
        """
        diamond blastp --outfmt {params.format}\
            --out   {output.tsv6}\
            --db    {params.db}\
            --query {input.query}\
            {params.extra_args}
        perl -i -ne 'print "{wildcards.genome}\\t" . "$_"' {output.tsv6}
        """


rule bind_blasts:
    input:
        ALL_BLASTS,
    output:
        f"{RESULTS}/{BLASTS_TSV}",
    params:
        header=BLAST_HEADER,
    shell:
        """
        cat - {input} >| {output} <<< '{params.header}'
        """


rule all_proteins:
    input:
        rules.bind_blasts.output,
    output:
        f"{RESULTS}/{BLASTS_FAA}",
    params:
        width="80",
    shell:
        """
        workflow/scripts/blast2faa.R {input} 2> /dev/null | fasta_unique | fasta_pretty -w={params.width} >| {output}
        """


rule interproscan_xml:
    input:
        faa=rules.all_proteins.output,
    output:
        xml=f"{RESULTS}/{ISCAN_XML}",
    params:
        temp="/tmp",
    threads: workflow.cores
    shell:
        """
        interproscan.sh --formats XML\
                        --input {input.faa} \
                        --outfile {output.xml} \
                        --cpu {threads} \
                        --tempdir {params.temp} \
                        --goterms
        """


rule interproscan_tsv:
    input:
        xml=rules.interproscan_xml.output.xml,
    output:
        tsv=f"{RESULTS}/{ISCAN_TSV}",
    params:
        header=ISCAN_HEADER,
        temp="/tmp",
    shell:
        """
        interproscan.sh --mode convert \
                        --formats TSV \
                        --input {input.xml} \
                        --outfile {output.tsv}.temp \
                        --goterms \
                        --enable-tsv-residue-annot

        cat - {output.tsv}.temp >| {output.tsv} <<< '{params.header}'

        rm {output.tsv}.temp
        """


rule pids:
    input:
        tsv=rules.bind_blasts.output,
        faa=rules.all_proteins.output,
    output:
        f"{RESULTS}/{BLASTS_PID}",
    shell:
        """
        sed '1d' {input.tsv} | perl -ape '$_ = $F[3] . "\\n"' | sort | uniq >| {output}

        N_FAA=`grep -c '^>' {input.faa}`
        N_PID=`grep -c '^'  {input.tsv}` # wc -l clutters the output, so equality (==) fails

        # Sanity check, N == M
        # N unique faas
        # M unique pids
        # if [[ "$N_FAA" -ne "$N_PID" ]]; then printf "Fatal Error:\\nN unique fasta entries differ from\\nM unique protein ids.\\n" && exit 1; fi
        """


rule hits:
    input:
        cds=rules.cds.output.cds,
        pids=rules.pids.output,
    output:
        f"{RESULTS_GENOMES}/{{genome}}/{{genome}}_hits.tsv",
    shell:
        """
        workflow/scripts/cds2hits.R {input.pids} {input.cds} >| {output}
        """


rule bind_hits:
    input:
        ALL_HITS,
    output:
        f"{RESULTS}/hits.tsv",
    threads: workflow.cores
    default_target: True
    shell:
        """
        workflow/scripts/bind_hits.R {threads} {input} >| {output}
        """


rule mappings:
    input:
        iscan=rules.interproscan_tsv.output,
        blasts=rules.bind_blasts.output,
    output:
        f"{RESULTS}/mappings_raw.tsv",
    params:
        config=workflow.configfiles[0],
    # default_target: True
    shell:
        """
        workflow/scripts/mappings.R {params.config} {input.iscan} {input.blasts} >| {output}
        """


rule filter_mappings:
    input:
        raw=rules.mappings.output,
    output:
        filtered=f"{RESULTS}/mappings.tsv",
    params:
        config=workflow.configfiles[0],
    default_target: True
    shell:
        """
        workflow/scripts/filter_mappings.R {params} {input} >| {output}
        """


# inputs_mappingsmappings_inputs = (Path(rules.mappings.output[0]), Path(rules.filter_mappings.output[0]))
# for input_map in inputs_mappings:
#     rule:
#         name: f"{input_map.stem}_wide"
#         input: f"{input_map}"
#         output: f"{input_map.stem}_wide.tsv"
#         shell: "workflow/scripts/make_wide.R {input} >| {output}"
