include: "rules/globals.smk"
include: "rules/download.smk"


rule all:
    input:
        f"{RESULTS}/.genomes_raw.tsv",


rule hmmer_input:
    input:
        ALL_FAAS,
    output:
        f"{RESULTS}/.input_faas.txt",
    run:
        with open(f"{output}", "w") as fh:
            for faa in ALL_FAAS:
                fh.write(f"{faa}\n")


rule hmmer:
    input:
        faas=rules.hmmer_input.output,
    output:
        tsv=ensure(f"{RESULTS}/hmmer.tsv", non_empty=True),
    params:
        queries=f"{IN_QUERIES}",
    shell:
        r"""
        workflow/scripts/hmmer.py {params} {input} {output}
        """


rule get_neighbors:
    input:
        hmmer=rules.hmmer.output,
    output:
        neighbors=ensure(f"{RESULTS}/neighbors.tsv", non_empty=True),
    threads: workflow.cores
    params:
        N=N_NEIGHBORS,
        gdir=f"{RESULTS}/genomes",  # Se convertira en output
    shell:
        """
        workflow/scripts/neighbors.R {threads} {params} {input} >| {output}
        """


rule all_faa:
    input:
        neighbors=rules.get_neighbors.output,
    output:
        faa=f"{RESULTS}/all.faa",
    params:
        faa_width=FAA_WIDTH,
        db=f"{RESULTS_GENOMES}",
    threads: workflow.cores
    shell:
        r"""
        workflow/scripts/harvest.R {params} {threads} {input} >| {output}
        """


rule split_faa:
    input:
        faa=rules.all_faa.output,
    output:
        pieces=directory(f"{RESULTS}/.pieces_faa"),
    params:
        batch_size=BATCH_SIZE,
    run:
        #!/usr/bin/env python
        from pathlib import Path

        from Bio import SeqIO

        IN_FAA = Path(f"{input}")
        OUT_PIECES = Path(f"{output}")
        BATCH_SIZE = int(f"{params}")
        FORMAT = "fasta"
        OUT_LEN = FAA_WIDTH

        # main
        in_faa = SeqIO.parse(IN_FAA, FORMAT)
        OUT_PIECES.mkdir()
        batch = []
        ibatch = 0


        def write(batch, out_file, wrap=60):
            with open(out_file, "w") as hout:
                w = SeqIO.FastaIO.FastaWriter(hout, wrap=wrap)
                for seq in batch:
                    w.write_record(seq)


        for idx, seq in enumerate(in_faa):
            batch.append(seq)

            if (idx + 1) % BATCH_SIZE == 0:
                ibatch += 1
                piece = OUT_PIECES / f"{ibatch}.faa"
                write(batch, piece, OUT_LEN)
                batch = []

        if len(batch) > 0:
            ibatch += 1
            piece = OUT_PIECES / f"{ibatch}.faa"
            write(batch, piece, OUT_LEN)


rule interproscan:
    input:
        faa_dir=rules.split_faa.output,
    output:
        tsv=f"{RESULTS}/.iscan_raw.tsv",
    params:
        tmp="/tmp",
        pieces=f"{RESULTS}/.pieces_iscan",
    threads: workflow.cores
    cache: True
    run:
        import re
        import shutil
        import subprocess as sp
        from pathlib import Path

        IN_DIR = Path(f"{input}")
        OUT_FILE = Path(f"{output}")

        OUT_DIR = Path(f"{params.pieces}")
        CPUS = int(f"{threads}")
        ISCAN_TMP = Path(f"{params.tmp}")


        def cat(*files, out_file) -> None:

            with open(out_file, "wb") as hout:
                for file in files:
                    with open(file, "rb") as hfile:
                        shutil.copyfileobj(hfile, hout)


        def gen_cmd(in_faa):
            """
    Output formats:
    Default for protein sequences are TSV, XML and GFF3
    """
            cmd = [
                "interproscan.sh",
                "--input",
                str(in_faa),
                "--cpu",
                str(CPUS),
                "--tempdir",
                str(ISCAN_TMP),
                "--goterms",
                "--enable-tsv-residue-annot",
            ]
            return cmd

            # main


        OUT_DIR.mkdir()
        in_faas = [
            (IN_DIR / i).resolve()
            for i in os.listdir(IN_DIR)
            if re.search(r"\d+\.faa$", i)
        ]

        for in_faa in in_faas:
            sp.run(gen_cmd(in_faa), cwd=OUT_DIR, check=True)

        out_tsvs = [
            OUT_DIR / i for i in os.listdir(OUT_DIR) if re.search(r"\w+\.tsv$", i)
        ]

        cat(*out_tsvs, out_file=OUT_FILE)


rule add_header_iscan:
    input:
        tsv=rules.interproscan.output,
    output:
        tsv=f"{RESULTS}/iscan.tsv",
    shell:
        """
        # Annotate headers
        workflow/scripts/add_header_iscan.R {params} {input} >| {output}
        """


rule get_archs:
    input:
        tsv=rules.add_header_iscan.output,
    output:
        archs=f"{RESULTS}/archs.tsv",
        pidrow=f"{RESULTS}/archs_pidrow.tsv",
        code=f"{RESULTS}/archs_code.tsv",
    shell:
        """
        workflow/scripts/archs.R {input} {output}
        """


rule get_absence_presence:
    input:
        taxa=rules.join_genomes_taxallnomy.output,
        proteins=rules.hmmer.output,
        domains=rules.get_archs.output.archs,
    output:
        TGPD=f"{RESULTS}/TGPD.tsv",
        absence_presence=f"{RESULTS}/absence_presence.tsv",
    shell:
        """
        workflow/scripts/absence_presence.R {input} {output}
        """
