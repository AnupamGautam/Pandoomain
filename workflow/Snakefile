include: "rules/globals.smk"  # no rules only globals, asserts, and utils
include: "rules/download.smk"


# include: "rules/blastp.smk"
# include: "rules/interproscan.smk"


rule all:
    input:
        f"{RESULTS}/genome_pid_query.tsv",
        f"{RESULTS}/pids.txt",
        f"{RESULTS}/hits.tsv",
        f"{RESULTS}/pairs.tsv",
        f"{RESULTS}/genomes_metadata.tsv",


SPLITS = f"{RESULTS}/splits_hmmer"
HEADER_HMMER_L = [
    "genome",
    "pid",
    "query",
    "score",
    "start",
    "end",
    "included",
    "reported",
    "pid_description",
    "query_description",
]
HEADER_HMMER = "\t".join(HEADER_HMMER_L)


rule hmmer_input:
    input:
        ALL_FAAS,
    output:
        f"{RESULTS}/.input_faas.txt",
    run:
        with open(f"{output}", "w") as fh:
            for faa in ALL_FAAS:
                fh.write(f"{faa}\n")


rule hmmer:
    input:
        faas=rules.hmmer_input.output,
    output:
        tsv=f"{RESULTS}/hmmer_raw.tsv",
    threads: workflow.cores * 4
    params:
        splits=SPLITS,
        split_size=1024,
        queries=IN_QUERIES,
        parallel_str=f"{SPLITS}/hmmer_" + "{#}.tsv {}",
        header=HEADER_HMMER,
        tmp=f"{RESULTS}/hmmer_raw.tsv.tmp",
    shell:
        r"""
        mkdir -p {params.splits}
        parallel -N {params.split_size} --progress -j {threads} 'workflow/scripts/hmmer.py {params.queries} {params.parallel_str}' :::: {input}
        fd -e tsv . {params.splits} | xargs cat >| {params.tmp}
        printf "{params.header}\n" | cat - {params.tmp} >| {output}
        rm -r {params.splits} {params.tmp}
        """


rule hmmer_filter:
    input:
        tsv=rules.hmmer.output.tsv,
    output:
        f"{RESULTS}/genome_pid_query.tsv",
    shell:
        r"""
        workflow/scripts/genome_pid_query.R {input} >| {output}
        """


rule hits_input:
    input:
        ALL_CDS,
    output:
        f"{RESULTS}/.input_cds.txt",
    run:
        with open(f"{output}", "w") as fh:
            for cds in ALL_CDS:
                fh.write(f"{cds}\n")


HITS_HEADER_L = [
    "genome",
    "pid",
    "gene",
    "order",
    "start",
    "end",
    "contig",
    "strand",
    "locus_tag",
    "product",
]
HEADER_HITS = "\t".join(HITS_HEADER_L)
SPLITS_HITS = f"{RESULTS}/splits_hits"


rule pids:
    input:
        GPQ=rules.hmmer_filter.output,
    output:
        pids=f"{RESULTS}/pids.txt",
    shell:
        r"""
        perl -ane '$_ = "$F[1]\n"; print if $. != 1;' {input} | sort | uniq > {output}
        """


rule hitsNH:
    input:
        cds=rules.hits_input.output,
        pids=rules.pids.output,
    output:
        f"{RESULTS}/.hitsNH.tsv",
    shell:
        r"""
        set +e

        parallel --progress 'grep --no-filename --fixed-string -f {input.pids} {{}}' :::: {input.cds} >| {output}

        exit 0 # grep returns exit status 1 on non-match
        """


rule hits:
    input:
        hitNH=rules.hitsNH.output,
    output:
        f"{RESULTS}/hits.tsv",
    params:
        header=HEADER_HITS,
    shell:
        r"""
        printf "{params}\n" | cat - {input} >| {output}
        """


rule pairs:
    input:
        hits=rules.hits.output,
        GPQ=rules.hmmer_filter.output,
    output:
        pairs=f"{RESULTS}/pairs.tsv",
        hitsq=f"{RESULTS}/hits_query.tsv",
    threads: workflow.cores
    params:
        config=workflow.configfiles[0],
    shell:
        r"""
        workflow/scripts/pairs.R {params.config} {input.hits} {input.GPQ} {output.hitsq} {threads} >| {output}
        """
